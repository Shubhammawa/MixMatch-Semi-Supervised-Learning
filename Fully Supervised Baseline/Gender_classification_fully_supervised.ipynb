{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_classification_fully_supervised.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "44TwcTyKy289",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import random_split\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVVxLPgyzEFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AAF_TRAIN_PATH = 'drive/My Drive/AWL Internship/MixMatch/AAF_Gender_Classification/AAF_train_MixMatch.xlsx'\n",
        "AAF_TEST_PATH = 'drive/My Drive/AWL Internship/MixMatch/AAF_Gender_Classification/AAF_test_MixMatch.xlsx'\n",
        "!unzip -q 'drive/My Drive/AWL Internship/AAF Dataset/extracted_original-20'\n",
        "AAF_IMAGE_PATH = 'extracted_original-20'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJHsEgp7zJbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = 0\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "NUM_LABELLED = 1000\t#No of labelled examples to be used in MixMatch\n",
        "DEVICE = torch.device(\"cuda:%d\" % CUDA)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ66Mz5czK5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AAF_Dataset(Dataset):\n",
        "\t''' Custom Dataset for loading AAF Dataset images'''\n",
        "\n",
        "\tdef __init__(self, csv_path, img_dir, transform):\n",
        "\t\t\n",
        "\t\tdf = pd.read_excel(csv_path)\n",
        "\t\tself.img_dir = img_dir\n",
        "\t\tself.transform = transform\n",
        "\t\tself.csv_path = csv_path\n",
        "\t\tself.gender = df['Gender'].values\n",
        "\t\tself.filename = df['Image'].values\n",
        "\t\n",
        "\t#def preprocess(self):\n",
        "\t''' Any further preprocessing required in the data\n",
        "\t\tcan be performed here'''\n",
        "\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\n",
        "\t\timg = Image.open(os.path.join(self.img_dir,\n",
        "\t\t\t\t\t\t\t\t\tself.filename[index]))\n",
        "\t\timg = self.transform(img)\n",
        "\t\ty_true = self.gender[index]\n",
        "\t\ty_true = torch.tensor(y_true, dtype=torch.float32)\n",
        "\t\t\n",
        "\t\treturn img, y_true\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.gender.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KmEvyCAzNcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_transform = transforms.Compose([transforms.Resize((96,96)),\n",
        "\t\t\t\t\t\t\ttransforms.ToTensor()])\t\n",
        "\n",
        "sample_batch_size = 4\n",
        "sample_dataset = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "sample_loader = DataLoader(dataset=sample_dataset, batch_size=sample_batch_size, shuffle=True)\n",
        "\n",
        "dataiter = iter(sample_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "#print(y_true.shape)\n",
        "\n",
        "#print(images[0])\n",
        "print(images[0].shape)\n",
        "print(labels[0].item())\n",
        "#print(y_true[0])\n",
        "\n",
        "def imshow(img, title):\n",
        "    '''Function imshow: Helper function to display an image'''\n",
        "    plt.figure(figsize=(sample_batch_size * 4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def show_batch_images(dataloader):\n",
        "    '''Function show_batch_images: Helper function to display images with their true ages'''\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    img = torchvision.utils.make_grid(images)\n",
        "    imshow(img, title = 'Images')\n",
        "    print(labels)\n",
        "    #print(y_true)\n",
        "    #print(gender)\n",
        "    #print(images)\n",
        "    \n",
        "    return images, labels\n",
        "images, labels = show_batch_images(sample_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiYujFnDzQPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AAF_train_full = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "AAF_train, _ = random_split(AAF_train_full, [NUM_LABELLED, len(AAF_train_full) - NUM_LABELLED])\n",
        "\n",
        "trainloader = DataLoader(AAF_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "AAF_test = AAF_Dataset(csv_path=AAF_TEST_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "\n",
        "testloader = DataLoader(AAF_test, batch_size= BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F-6OTWM3CpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(AAF_train), len(AAF_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf-0nma1zePP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = nn.CrossEntropyLoss(reduction='sum')\n",
        "l2_loss = nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNB3k-czejR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = models.wide_resnet50_2(pretrained=True)\n",
        "model_1.to(DEVICE)\n",
        "print(summary(model_1, (3, 96, 96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFntq_Igzesz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gender_Classifier(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Gender_Classifier, self).__init__()\n",
        "\n",
        "            self.fc1 = nn.Linear(1000, 100)\n",
        "            self.fc2 = nn.Linear(100, 10)\n",
        "            self.fc3 = nn.Linear(10,2)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1(x)\n",
        "            x = self.fc2(x)\n",
        "            logits = self.fc3(x)\n",
        "            return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZqCyrbSze2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = Gender_Classifier()\n",
        "model = nn.Sequential(model_1, model_2)\n",
        "model.to(DEVICE)\n",
        "print(summary(model, (3,96,96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfrD8RlDzfMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYgac11Y0GCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "num_batches = 0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch_idx, (x, y) in enumerate(trainloader):\n",
        "\t\tx = x.to(DEVICE)\n",
        "\t\ty = y.to(DEVICE)\n",
        "\t\t\n",
        "\t\ty_pred = model(x)\n",
        "\t\t\n",
        "\t\tloss = cross_entropy(y_pred, y.long())\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\tloss.backward()\n",
        "  \n",
        "\t\toptimizer.step()\n",
        "\t\tif(batch_idx % 50 == 0):\n",
        "\t\t\ts = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f '\n",
        "\t\t\t\t% (epoch+1, NUM_EPOCHS, batch_idx,\n",
        "\t\t\t\t\tlen(AAF_train)//BATCH_SIZE, loss))\n",
        "\t\t\tprint(s)\n",
        "\t\n",
        "\ts = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n",
        "\tprint(s)\n",
        "\tmodel.eval()\n",
        "\ty_true = []\n",
        "\ty_pred = []\n",
        "\twith torch.set_grad_enabled(False):\n",
        "\t\tcorrect_results = 0\n",
        "\t\tfor batch_idx, (img, label) in enumerate(testloader):\n",
        "\t\t\timg = img.to(DEVICE)\n",
        "\t\t\tlabel = label.to(DEVICE)\n",
        "\n",
        "\t\t\tlogits = model(img)\n",
        "\t\t\tprobas = nn.functional.softmax(logits, dim=1)\n",
        "\t\t\tpred = torch.argmax(probas, dim=1)\n",
        "\t\t\ty_true.extend(label.cpu().numpy())\n",
        "\t\t\ty_pred.extend(pred.cpu().numpy())\n",
        "\tprint(accuracy_score(y_true, y_pred))\n",
        "\tprint(f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWs0kYFP0IfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.set_grad_enabled(False):\n",
        "    correct_results = 0\n",
        "    for batch_idx, (img, label) in enumerate(trainloader):\n",
        "        img = img.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        logits = model(img)\n",
        "        probas = nn.functional.softmax(logits, dim=1)\n",
        "        pred = torch.argmax(probas, dim=1)\n",
        "        y_true.extend(label.cpu().numpy())\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "print(f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSn-VuEx7ctt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_naive = np.zeros(len(y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyRBuJKqFj83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(accuracy_score(y_true, y_naive))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgHcaVXFn3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}