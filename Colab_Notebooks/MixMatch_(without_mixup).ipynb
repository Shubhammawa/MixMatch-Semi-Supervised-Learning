{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MixMatch_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15Jy8FdH6MfAV82rM6gvVFbwxTr7CUxlT",
      "authorship_tag": "ABX9TyNFSzbgiXVPb+/dRKrIyQAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python37564bitselfconda0236a4c4dc054346817800797604c19b",
      "display_name": "Python 3.7.5 64-bit ('self': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awl-shubham-mawa/AWL-Internship/blob/master/MixMatch_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j5FetHu765w",
        "colab_type": "text"
      },
      "source": [
        "### 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euD3qvtNQGxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import random_split\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38JAvhab790n",
        "colab_type": "text"
      },
      "source": [
        "### 2. Filepaths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywmc3z9BU3cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AAF_TRAIN_PATH = 'drive/My Drive/AWL Internship/MixMatch/AAF_Gender_Classification/AAF_train_MixMatch.xlsx'\n",
        "AAF_TEST_PATH = 'drive/My Drive/AWL Internship/MixMatch/AAF_Gender_Classification/AAF_test_MixMatch.xlsx'\n",
        "!unzip -q 'drive/My Drive/AWL Internship/AAF Dataset/extracted_original-20'\n",
        "AAF_IMAGE_PATH = 'extracted_original-20'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTOla_XA8Aj5",
        "colab_type": "text"
      },
      "source": [
        "### 3. Arguments/Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYB0WVHUU9XW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "66ff0f71-230c-4bef-fc43-43a271a29acc"
      },
      "source": [
        "CUDA = 0\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "lambda_u = 1\n",
        "NUM_LABELLED = 1000\t#No of labelled examples to be used in MixMatch\n",
        "DEVICE = torch.device(\"cuda:%d\" % CUDA)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpP-8AMV8Gxh",
        "colab_type": "text"
      },
      "source": [
        "### 4. AAF Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex-ZykbPVBkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AAF_Dataset(Dataset):\n",
        "\t''' Custom Dataset for loading AAF Dataset images'''\n",
        "\n",
        "\tdef __init__(self, csv_path, img_dir, transform):\n",
        "\t\t\n",
        "\t\tdf = pd.read_excel(csv_path)\n",
        "\t\tself.img_dir = img_dir\n",
        "\t\tself.transform = transform\n",
        "\t\tself.csv_path = csv_path\n",
        "\t\tself.gender = df['Gender'].values\n",
        "\t\tself.filename = df['Image'].values\n",
        "\t\n",
        "\t#def preprocess(self):\n",
        "\t''' Any further preprocessing required in the data\n",
        "\t\tcan be performed here'''\n",
        "\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\n",
        "\t\timg = Image.open(os.path.join(self.img_dir,\n",
        "\t\t\t\t\t\t\t\t\tself.filename[index]))\n",
        "\t\timg = self.transform(img)\n",
        "\t\ty_true = self.gender[index]\n",
        "\t\ty_true = torch.tensor(y_true, dtype=torch.float32)\n",
        "\t\t\n",
        "\t\treturn img, y_true\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.gender.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD1D9-uk8NEo",
        "colab_type": "text"
      },
      "source": [
        "### 5. Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa2lLZcc8K_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_transform = transforms.Compose([transforms.Resize((96,96)),\n",
        "\t\t\t\t\t\t\ttransforms.ToTensor()])\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMPk3PRA8b6N",
        "colab_type": "text"
      },
      "source": [
        "### 6. Sample batch for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOuSyI_0eHe-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "422e36fe-2514-444c-d268-49c7c3139329"
      },
      "source": [
        "sample_batch_size = 4\n",
        "sample_dataset = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "sample_loader = DataLoader(dataset=sample_dataset, batch_size=sample_batch_size, shuffle=True)\n",
        "\n",
        "dataiter = iter(sample_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(\"Batch shape (images): \",images.shape)\n",
        "print(\"Batch shape (labels): \", labels.shape)\n",
        "#print(y_true.shape)\n",
        "\n",
        "#print(images[0])\n",
        "# print(images[0].shape)\n",
        "# print(labels[0].item())\n",
        "#print(y_true[0])\n",
        "\n",
        "def imshow(img, title):\n",
        "    '''Function imshow: Helper function to display an image'''\n",
        "    plt.figure(figsize=(sample_batch_size * 4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def show_batch_images(dataloader):\n",
        "    '''Function show_batch_images: Helper function to display images with their true ages'''\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    img = torchvision.utils.make_grid(images)\n",
        "    imshow(img, title = 'Images')\n",
        "    print(\"Labels: \",labels)\n",
        "    \n",
        "    return images, labels\n",
        "images, labels = show_batch_images(sample_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDQXzNM80iS",
        "colab_type": "text"
      },
      "source": [
        "### 7. Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0DGgV_eeOaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e50fbb54-d7ec-4c81-d58f-9926c8b76409"
      },
      "source": [
        "AAF_train = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "\n",
        "AAF_train_labelled, AAF_train_unlabelled = random_split(AAF_train, [NUM_LABELLED, len(AAF_train) - NUM_LABELLED])\n",
        "\n",
        "trainloader_labelled = DataLoader(AAF_train_labelled, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_unlabelled = DataLoader(AAF_train_unlabelled, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "AAF_test = AAF_Dataset(csv_path=AAF_TEST_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "\n",
        "testloader = DataLoader(AAF_test, batch_size= BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Labelled examples: \" + str(len(AAF_train_labelled)) + \"\\nUnlabelled examples: \" \n",
        "      + str(len(AAF_train_unlabelled)) + \"\\nTest examples: \" + str(len(AAF_test)))\n",
        "\n",
        "# dataiter = iter(trainloader_labelled)\n",
        "# images, labels = dataiter.next()\n",
        "# print(labels[:])\n",
        "# print(len(AAF_train_labelled), len(AAF_train_unlabelled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtLdzmUz89H4",
        "colab_type": "text"
      },
      "source": [
        "### 8. MixMatch Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q5DyxYPeSjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(batch_img, K = 2):\n",
        "\t'''Function augment_image:\n",
        "\t\tInput: PIL Image/Torch Tensor\n",
        "\t\tOutput: K number of augmented images'''\n",
        "\t\n",
        "\tbatch_augment_images = []\n",
        "\tfor i in range(batch_img.shape[0]):\n",
        "\t\timg = batch_img[i]\n",
        "\t\timg = TF.to_pil_image(img.cpu())\n",
        "\t\timg_1 = TF.to_tensor(TF.adjust_brightness(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\timg_2 = TF.to_tensor(TF.adjust_contrast(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\timg_3 = TF.to_tensor(TF.adjust_saturation(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\t\n",
        "\t\timg_4 = TF.to_tensor(TF.hflip(img))\n",
        "\t\timg_5 = TF.to_tensor(TF.rotate(img, angle=np.random.uniform(-10,10)))\n",
        "\n",
        "\t\timg_6 = TF.to_tensor(TF.to_grayscale(img, num_output_channels=3))\n",
        "\t\timg_7 = TF.to_tensor(TF.adjust_gamma(img, np.random.uniform(0.5, 1.5)))\n",
        "\n",
        "\t\trandom_numbers = random.sample(range(1, 8), K)\n",
        "\t\timg_dict = {'1': img_1, '2': img_2, '3': img_3, '4': img_4, '5': img_5, '6': img_6, '7': img_7}\n",
        "\n",
        "\t\taugment_images = []\n",
        "\t\tfor i in random_numbers:\n",
        "\t\t\taugment_images.append(img_dict[str(i)])\n",
        "\t\tbatch_augment_images.append(augment_images)\n",
        "\treturn batch_augment_images\n",
        "\n",
        "def label_guessing(model, augment_images, device):\n",
        "\t''' Function label_guessing\n",
        "\t\tInput: Classifier model, K augmentations of the unlabelled data\n",
        "\t\tOuput: Calls augment_image function, makes predictions for the K augmentations and averages them to get the guessed\n",
        "\t\t\t\tlabels for unlabelled data.\n",
        "\t\t'''\n",
        "\tpredictions = []\n",
        "\n",
        "\tfor i in range(0,len(augment_images)):\n",
        "\n",
        "\t\timg = torch.stack(augment_images[i], dim=0)\n",
        "\t\timg = img.to(device)\n",
        "\t\tlogits = model(img)\n",
        "\t\tprobas = nn.functional.softmax(logits, dim=1)\n",
        "\t\tpredictions.append(probas)\n",
        "\tpredictions = torch.stack(predictions,dim=0)\n",
        "\tq_hat = torch.mean(predictions, dim=1)\n",
        "\n",
        "\treturn q_hat\n",
        "\n",
        "def sharpen(p, T=0.5):\n",
        "\tp_sharp = torch.pow(p, 1/T)/(torch.sum(torch.pow(p, 1/T), dim=0))\n",
        "\treturn p_sharp\n",
        "\n",
        "def mixup(x1,y1,x2,y2,alpha=0.75):\n",
        "    l = np.random.beta(alpha,alpha)\n",
        "    l = max(l,1-l)\n",
        "    x = l * x1 + (1-l) * x2\n",
        "    y = l* y1 + (1-l) * y2\n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1t5TB2x9DNv",
        "colab_type": "text"
      },
      "source": [
        "### 9. MixMatch Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lkQ9e9DeYv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixMatch_Dataset(Dataset):\n",
        "\t'''Supply a batch of labelled and unlabelled data, X and U.'''\n",
        "\t\n",
        "\tdef __init__(self, Labelled_data, Unlabelled_data):\n",
        "\t\tself.Labelled_data = Labelled_data\n",
        "\t\tself.Unlabelled_data = Unlabelled_data\n",
        "  \n",
        "\tdef __getitem__(self, index):\n",
        "\t\t\n",
        "\t\tsize_labelled = len(self.Labelled_data)\n",
        "\t\tsize_unlabelled = len(self.Unlabelled_data)\n",
        "\t\tif(index < size_labelled):\n",
        "\t\t\tl_index = index\n",
        "\t\telse:\n",
        "\t\t\tl_index = np.random.randint(0, size_labelled)\n",
        "\t\tif(index < size_unlabelled):\n",
        "\t\t\tu_index = index\n",
        "\t\telse:\n",
        "\t\t\tu_index = index - size_unlabelled\n",
        "\t\t#print(l_index)\n",
        "\t\tx = self.Labelled_data[l_index][0]\n",
        "\t\ty = self.Labelled_data[l_index][1]\n",
        "\t\tu = self.Unlabelled_data[u_index][0]\n",
        "\n",
        "\t\treturn x, y, u\n",
        "\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn max(len(self.Labelled_data), len(self.Unlabelled_data))\n",
        "\n",
        "MixMatch_dataset = MixMatch_Dataset(Labelled_data=AAF_train_labelled, Unlabelled_data=AAF_train_unlabelled)\n",
        "MixMatch_loader = DataLoader(MixMatch_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8jVsEIA9ImT",
        "colab_type": "text"
      },
      "source": [
        "### 10. Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ISLQQAVevNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = nn.CrossEntropyLoss(reduction='sum')\n",
        "l2_loss = nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYE_GeXT9NIX",
        "colab_type": "text"
      },
      "source": [
        "### 11. Wide-Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOCKWPqcezTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b35656c8-737b-48c6-90d2-9705911915d8"
      },
      "source": [
        "model_1 = models.wide_resnet50_2(pretrained=True)\n",
        "model_1.to(DEVICE)\n",
        "print(summary(model_1, (3, 96, 96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVIhHpLr9XsK",
        "colab_type": "text"
      },
      "source": [
        "### 12. Gender Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNC-1Lye1cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gender_Classifier(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Gender_Classifier, self).__init__()\n",
        "\n",
        "            self.fc1 = nn.Linear(1000, 100)\n",
        "            self.fc2 = nn.Linear(100, 10)\n",
        "            self.fc3 = nn.Linear(10,2)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1(x)\n",
        "            x = self.fc2(x)\n",
        "            logits = self.fc3(x)\n",
        "            return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxN1IBAY9iZu",
        "colab_type": "text"
      },
      "source": [
        "### 13. Stack classifier onto the Wide-Resnet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEFMAIfGe4HK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a23d3e9-12e8-4a94-c6c5-36a225258a99"
      },
      "source": [
        "model_2 = Gender_Classifier()\n",
        "model = nn.Sequential(model_1, model_2)\n",
        "model.to(DEVICE)\n",
        "print(summary(model, (3,96,96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0hbyhdD9v1E",
        "colab_type": "text"
      },
      "source": [
        "### 14. Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh3MmOxCe6_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OngDFjjc9zw8",
        "colab_type": "text"
      },
      "source": [
        "### 15. Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEWS5C1Ke8-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "8835269f-b771-471a-9dd3-acaad3964660"
      },
      "source": [
        "start_time = time.time()\n",
        "num_batches = 0\n",
        "#costs = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch_idx, (x, y, u) in enumerate(MixMatch_loader):\n",
        "\t\tx = x.to(DEVICE)\n",
        "\t\ty = y.to(DEVICE)\n",
        "\t\tu = u.to(DEVICE)\n",
        "\t\tnum_batches += 1\n",
        "\n",
        "\t\taugment_images = augment_image(u)\n",
        "\t\tq_hat = label_guessing(model, augment_images, device=DEVICE)\n",
        "\t\tq = torch.argmax(sharpen(q_hat), dim = 1)\n",
        "\t\t\n",
        "\t\ty_pred = model(x)\n",
        "  \n",
        "\t\tq_pred_logits = model(u)\n",
        "\t\tq_pred_probas = nn.functional.softmax(q_pred_logits, dim=1)\n",
        "\t\tq_pred = torch.argmax(q_pred_probas, dim=1)\n",
        "\t\t\n",
        "\t\tcost_labelled = cross_entropy(y_pred, y.long())\n",
        "\t\tcost_unlabelled = l2_loss(q_pred, q.float())\n",
        "\n",
        "\t\tif(num_batches < 1000):\n",
        "\t\t\tramp = num_batches/1000\n",
        "\t\telse:\n",
        "\t\t\tramp = 1\n",
        "\t\tloss = cost_labelled + ramp*lambda_u*cost_unlabelled\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\tloss.backward()\n",
        "\t\t#costs.append(loss)\n",
        "\t\toptimizer.step()\n",
        "\t\tif(batch_idx % 50 == 0):\n",
        "\t\t\ts = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f | Labelled loss: %.4f | Unlabelled loss: %.4f'\n",
        "\t\t\t\t% (epoch+1, NUM_EPOCHS, batch_idx,\n",
        "\t\t\t\t\tlen(MixMatch_dataset)//BATCH_SIZE, loss, cost_labelled, cost_unlabelled))\n",
        "\t\t\tprint(s)\n",
        "\t\n",
        "\ts = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n",
        "\tprint(s)\n",
        "\tmodel.eval()\n",
        "\ty_true = []\n",
        "\ty_pred = []\n",
        "\twith torch.set_grad_enabled(False):\n",
        "\t\tfor batch_idx, (img, label) in enumerate(testloader):\n",
        "\t\t\timg = img.to(DEVICE)\n",
        "\t\t\tlabel = label.to(DEVICE)\n",
        "\n",
        "\t\t\tlogits = model(img)\n",
        "\t\t\tprobas = nn.functional.softmax(logits, dim=1)\n",
        "\t\t\tpred = torch.argmax(probas, dim=1)\n",
        "\t\t\ty_true.extend(label.cpu().numpy())\n",
        "\t\t\ty_pred.extend(pred.cpu().numpy())\n",
        "\tprint(accuracy_score(y_true, y_pred))\n",
        "\tprint(f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdgVwvoMfAG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "60eb8e36-b988-4f05-f6e3-200404351aa6"
      },
      "source": [
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.set_grad_enabled(False):\n",
        "    correct_results = 0\n",
        "    for batch_idx, (img, label) in enumerate(testloader):\n",
        "        img = img.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        logits = model(img)\n",
        "        probas = nn.functional.softmax(logits, dim=1)\n",
        "        pred = torch.argmax(probas, dim=1)\n",
        "        y_true.extend(label.cpu().numpy())\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "print(f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGpXHuKvmRho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}