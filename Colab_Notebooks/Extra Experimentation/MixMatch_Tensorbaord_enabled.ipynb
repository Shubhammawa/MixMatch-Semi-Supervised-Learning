{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MixMatch_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDZ42kpnAy0y",
        "colab_type": "text"
      },
      "source": [
        "### 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euD3qvtNQGxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import random_split\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWC4cIHWA28-",
        "colab_type": "text"
      },
      "source": [
        "### 2. Filepaths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywmc3z9BU3cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AAF_TRAIN_PATH = 'AAF_train_MixMatch.xlsx'\n",
        "AAF_TEST_PATH = 'AAF_test_MixMatch.xlsx'\n",
        "#!unzip -q 'extracted_original-20'\n",
        "AAF_IMAGE_PATH = 'extracted_original-20'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFaTBNxEA8ai",
        "colab_type": "text"
      },
      "source": [
        "### 3. Arguments/Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYB0WVHUU9XW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "400d6126-2a11-4219-b49f-aa59f79253d9"
      },
      "source": [
        "CUDA = 0\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "NUM_LABELLED = 1000\t#No of labelled examples to be used in MixMatch\n",
        "DEVICE = torch.device(\"cuda:%d\" % CUDA)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r6WmimzBA6L",
        "colab_type": "text"
      },
      "source": [
        "### 4. AAF Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex-ZykbPVBkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AAF_Dataset(Dataset):\n",
        "\t''' Custom Dataset for loading AAF Dataset images'''\n",
        "\n",
        "\tdef __init__(self, csv_path, img_dir, transform):\n",
        "\t\t\n",
        "\t\tdf = pd.read_excel(csv_path)\n",
        "\t\tself.img_dir = img_dir\n",
        "\t\tself.transform = transform\n",
        "\t\tself.csv_path = csv_path\n",
        "\t\tself.gender = df['Gender'].values\n",
        "\t\tself.filename = df['Image'].values\n",
        "\t\n",
        "\t#def preprocess(self):\n",
        "\t''' Any further preprocessing required in the data\n",
        "\t\tcan be performed here'''\n",
        "\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\n",
        "\t\timg = Image.open(os.path.join(self.img_dir,\n",
        "\t\t\t\t\t\t\t\t\tself.filename[index]))\n",
        "\t\timg = self.transform(img)\n",
        "\t\ty_true = self.gender[index]\n",
        "\t\ty_true = torch.tensor(y_true, dtype=torch.float32)\n",
        "\t\t\n",
        "\t\treturn img, y_true\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.gender.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSfgCtpABI5-",
        "colab_type": "text"
      },
      "source": [
        "### 5. Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a76U-gWoBHA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_transform = transforms.Compose([transforms.Resize((96,96)),\n",
        "\t\t\t\t\t\t\ttransforms.ToTensor()])\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIMqD2c9BN-o",
        "colab_type": "text"
      },
      "source": [
        "### 6. Sample batch for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOuSyI_0eHe-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "961fc537-8025-4e7e-c13a-20efd4755c9c"
      },
      "source": [
        "sample_batch_size = 4\n",
        "sample_dataset = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "sample_loader = DataLoader(dataset=sample_dataset, batch_size=sample_batch_size, shuffle=True)\n",
        "\n",
        "dataiter = iter(sample_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(\"Batch shape (images): \",images.shape)\n",
        "print(\"Batch shape (labels): \", labels.shape)\n",
        "#print(y_true.shape)\n",
        "\n",
        "#print(images[0])\n",
        "# print(images[0].shape)\n",
        "# print(labels[0].item())\n",
        "#print(y_true[0])\n",
        "\n",
        "def imshow(img, title):\n",
        "    '''Function imshow: Helper function to display an image'''\n",
        "    plt.figure(figsize=(sample_batch_size * 4, 4))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def show_batch_images(dataloader):\n",
        "    '''Function show_batch_images: Helper function to display images with their true ages'''\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    img = torchvision.utils.make_grid(images)\n",
        "    imshow(img, title = 'Images')\n",
        "    print(\"Labels: \",labels)\n",
        "    \n",
        "    return images, labels\n",
        "images, labels = show_batch_images(sample_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeKdspecBjOt",
        "colab_type": "text"
      },
      "source": [
        "### 7. Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0DGgV_eeOaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "20c202f8-a7d7-453a-a183-530105c669d8"
      },
      "source": [
        "AAF_train = AAF_Dataset(csv_path=AAF_TRAIN_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "\n",
        "AAF_train_labelled, AAF_train_unlabelled = random_split(AAF_train, [NUM_LABELLED, len(AAF_train) - NUM_LABELLED])\n",
        "\n",
        "trainloader_labelled = DataLoader(AAF_train_labelled, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_unlabelled = DataLoader(AAF_train_unlabelled, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "AAF_test = AAF_Dataset(csv_path=AAF_TEST_PATH, img_dir=AAF_IMAGE_PATH, transform=custom_transform)\n",
        "\n",
        "testloader = DataLoader(AAF_test, batch_size= BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Labelled examples: \" + str(len(AAF_train_labelled)) + \"\\nUnlabelled examples: \" \n",
        "      + str(len(AAF_train_unlabelled)) + \"\\nTest examples: \" + str(len(AAF_test)))\n",
        "\n",
        "# dataiter = iter(trainloader_labelled)\n",
        "# images, labels = dataiter.next()\n",
        "# print(labels[:])\n",
        "# print(len(AAF_train_labelled), len(AAF_train_unlabelled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9PYMisSBqQN",
        "colab_type": "text"
      },
      "source": [
        "### 8. MixMatch Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q5DyxYPeSjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(batch_img, K = 2):\n",
        "\t'''Function augment_image:\n",
        "\t\tInput: PIL Image/Torch Tensor\n",
        "\t\tOutput: K number of augmented images'''\n",
        "\t\n",
        "\tbatch_augment_images = []\n",
        "\tfor i in range(batch_img.shape[0]):\n",
        "\t\timg = batch_img[i]\n",
        "\t\timg = TF.to_pil_image(img.cpu())\n",
        "\t\timg_1 = TF.to_tensor(TF.adjust_brightness(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\timg_2 = TF.to_tensor(TF.adjust_contrast(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\timg_3 = TF.to_tensor(TF.adjust_saturation(img, np.random.uniform(0.5, 1.5)))\n",
        "\t\t\n",
        "\t\timg_4 = TF.to_tensor(TF.hflip(img))\n",
        "\t\timg_5 = TF.to_tensor(TF.rotate(img, angle=np.random.uniform(-10,10)))\n",
        "\n",
        "\t\timg_6 = TF.to_tensor(TF.to_grayscale(img, num_output_channels=3))\n",
        "\t\timg_7 = TF.to_tensor(TF.adjust_gamma(img, np.random.uniform(0.5, 1.5)))\n",
        "\n",
        "\t\trandom_numbers = random.sample(range(1, 8), K)\n",
        "\t\timg_dict = {'1': img_1, '2': img_2, '3': img_3, '4': img_4, '5': img_5, '6': img_6, '7': img_7}\n",
        "\n",
        "\t\taugment_images = []\n",
        "\t\tfor i in random_numbers:\n",
        "\t\t\taugment_images.append(img_dict[str(i)])\n",
        "\t\t#augment_images = torch.FloatTensor(augment_images)\n",
        "\t\tbatch_augment_images.append(augment_images)\n",
        "\t#batch_augment_images = torch.tensor(batch_augment_images)\n",
        "\treturn batch_augment_images\n",
        "\n",
        "def label_guessing(model, augment_images, device):\n",
        "\t''' Function label_guessing\n",
        "\t\tInput: Classifier model, K augmentations of the unlabelled data\n",
        "\t\tOuput: Calls augment_image function, makes predictions for the K augmentations and averages them to get the guessed\n",
        "\t\t\t\tlabels for unlabelled data.\n",
        "\t\t'''\n",
        "\tpredictions = []\n",
        "\t# augment_images = np.array(augment_images)\n",
        "\t# print(np.shape(augment_images))\n",
        "\tfor i in range(0,len(augment_images)):\n",
        "\t\t#print(np.shape(augment_images[i]))\n",
        "\t\t#augment_images[i] = augment_images[i].unsqueeze(0)\n",
        "\t\t#print(len(augment_images))\n",
        "\t\timg = torch.stack(augment_images[i], dim=0)\n",
        "\t\t#img = img.unsqueeze(0)\n",
        "\t\timg = img.to(device)\n",
        "\t\tlogits = model(img)\n",
        "\t\tprobas = nn.functional.softmax(logits, dim=1)\n",
        "\t\t#y_pred = torch.argmax(probas, dim=1)\n",
        "\t\tpredictions.append(probas)\n",
        "\tpredictions = torch.stack(predictions,dim=0)\n",
        "\tq_hat = torch.mean(predictions, dim=1)\n",
        "\n",
        "\treturn q_hat\n",
        "\n",
        "def sharpen(p, T=0.5):\n",
        "\tp_sharp = torch.pow(p, 1/T)/(torch.sum(torch.pow(p, 1/T), dim=0))\n",
        "\treturn p_sharp\n",
        "\n",
        "def mixup(x1,y1,x2,y2,alpha=0.75):\n",
        "    l = np.random.beta(alpha,alpha)\n",
        "    #print(l)\n",
        "    l = max(l,1-l)\n",
        "    x = l * x1 + (1-l) * x2\n",
        "    y = l* y1 + (1-l) * y2\n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-wmJhUBu_K",
        "colab_type": "text"
      },
      "source": [
        "### 9. MixMatch Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lkQ9e9DeYv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixMatch_Dataset(Dataset):\n",
        "\t'''Supply a batch of labelled and unlabelled data, X and U.'''\n",
        "\t\n",
        "\tdef __init__(self, Labelled_data, Unlabelled_data):\n",
        "\t\tself.Labelled_data = Labelled_data\n",
        "\t\tself.Unlabelled_data = Unlabelled_data\n",
        "  \n",
        "\tdef __getitem__(self, index):\n",
        "\t\t\n",
        "\t\tsize_labelled = len(self.Labelled_data)\n",
        "\t\tsize_unlabelled = len(self.Unlabelled_data)\n",
        "\t\t#print(size_labelled, size_unlabelled)\n",
        "\t\tif(index < size_labelled):\n",
        "\t\t\tl_index = index\n",
        "\t\t\t#print(1)\n",
        "\t\telse:\n",
        "\t\t\tl_index = int(index*len(self.Labelled_data)/len(self.Unlabelled_data))\n",
        "\t\t\t#print(0)\n",
        "\t\tif(index < size_unlabelled):\n",
        "\t\t\tu_index = index\n",
        "\t\telse:\n",
        "\t\t\tu_index = index - size_unlabelled\n",
        "\t\t#print(l_index)\n",
        "\t\tx = self.Labelled_data[l_index][0]\n",
        "\t\ty = self.Labelled_data[l_index][1]\n",
        "\t\tu = self.Unlabelled_data[u_index][0]\n",
        "\n",
        "\t\treturn x, y, u\n",
        "\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn max(len(self.Labelled_data), len(self.Unlabelled_data))\n",
        "\n",
        "MixMatch_dataset = MixMatch_Dataset(Labelled_data=AAF_train_labelled, Unlabelled_data=AAF_train_unlabelled)\n",
        "MixMatch_loader = DataLoader(MixMatch_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkhnU7ZvCELo",
        "colab_type": "text"
      },
      "source": [
        "### 10. Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ISLQQAVevNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = nn.CrossEntropyLoss(reduction='sum')\n",
        "l2_loss = nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2WFMTgCKVm",
        "colab_type": "text"
      },
      "source": [
        "### 11. Wide-Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOCKWPqcezTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b1d8b12-e0c2-4a3c-eb19-884077aa99bf"
      },
      "source": [
        "model_1 = models.wide_resnet50_2(pretrained=True)\n",
        "model_1.to(DEVICE)\n",
        "print(summary(model_1, (3, 96, 96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-kR8-f3Cldq",
        "colab_type": "text"
      },
      "source": [
        "### 12. Gender Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNC-1Lye1cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gender_Classifier(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Gender_Classifier, self).__init__()\n",
        "\n",
        "            self.fc1 = nn.Linear(1000, 100)\n",
        "            self.fc2 = nn.Linear(100, 10)\n",
        "            self.fc3 = nn.Linear(10,2)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.fc1(x)\n",
        "            x = self.fc2(x)\n",
        "            logits = self.fc3(x)\n",
        "            return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJywJaOACv9_",
        "colab_type": "text"
      },
      "source": [
        "### 13. Stack classifier onto the Wide-Resnet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEFMAIfGe4HK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2387d5b-820f-4906-8a8d-9bd67fd09848"
      },
      "source": [
        "model_2 = Gender_Classifier()\n",
        "model = nn.Sequential(model_1, model_2)\n",
        "model.to(DEVICE)\n",
        "print(summary(model, (3,96,96)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB9oJRZVC05C",
        "colab_type": "text"
      },
      "source": [
        "### 14. Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh3MmOxCe6_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ozObdQeR4DP",
        "colab_type": "text"
      },
      "source": [
        "### 15. Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMLtNGmqR2Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter()\n",
        "dataiter = iter(trainloader_labelled)\n",
        "images, labels = dataiter.next()\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid, 0)\n",
        "writer.add_graph(model, images.to(DEVICE))\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7dhwoQ0R89k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs --host=127.0.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NcBNcNkC4ht",
        "colab_type": "text"
      },
      "source": [
        "### 16. Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEWS5C1Ke8-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "b737ae40-8438-4488-8601-c5e4a7e5b7cc"
      },
      "source": [
        "start_time = time.time()\n",
        "num_batches = 0\n",
        "#costs = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch_idx, (x, y, u) in enumerate(MixMatch_loader):\n",
        "\t\tx = x.to(DEVICE)\n",
        "\t\ty = y.to(DEVICE)\n",
        "\t\tu = u.to(DEVICE)\n",
        "\t\tnum_batches += 1\n",
        "\n",
        "\t\taugment_images = augment_image(u, K=4)\n",
        "\t\tq_hat = label_guessing(model, augment_images, device=DEVICE)\n",
        "\t\tq = torch.argmax(sharpen(q_hat), dim = 1)\n",
        "\t\t\n",
        "\t\t# y_pred = model(x)\n",
        "  \n",
        "\t\t# q_pred_logits = model(u)\n",
        "\t\t# q_pred_probas = nn.functional.softmax(q_pred_logits, dim=1)\n",
        "\t\t# q_pred = torch.argmax(q_pred_probas, dim=1)\n",
        "\t\t\n",
        "\t\t# cost_labelled = cross_entropy(y_pred, y.long())\n",
        "\t\t# cost_unlabelled = l2_loss(q_pred, q.float())\n",
        "\t\t\n",
        "\t\twx = torch.cat([x,u])\n",
        "\t\twy = torch.cat([y,q])\n",
        "\n",
        "\t\tidx = torch.randperm(wx.shape[0])\n",
        "\n",
        "\t\tx_mix, y_mix = mixup(x, y, wx[idx[:int(len(idx)/2)]], wy[idx[:int(len(idx)/2)]])\n",
        "\t\tu_mix, q_mix = mixup(u, q, wx[idx[int(len(idx)/2):]], wy[idx[int(len(idx)/2):]])\n",
        "\n",
        "\t\ty_mix_pred = model(x_mix)\n",
        "\t\tq_mix_pred_logits = model(u_mix)\n",
        "\t\tq_mix_pred_probas = nn.functional.softmax(q_mix_pred_logits, dim=1)\n",
        "\t\tq_mix_pred = torch.argmax(q_mix_pred_probas, dim=1)\n",
        "\t\t\n",
        "\t\tcost_labelled = cross_entropy(y_mix_pred, y_mix.long())\n",
        "\t\tcost_unlabelled = l2_loss(q_mix_pred, q_mix)\n",
        "\n",
        "\t\tif(num_batches < 1000):\n",
        "\t\t\tramp = num_batches/1000\n",
        "\t\telse:\n",
        "\t\t\tramp = 1\n",
        "\t\tloss = cost_labelled + ramp*cost_unlabelled\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\tloss.backward()\n",
        "\n",
        "\t\t#costs.append(loss)\n",
        "\t\toptimizer.step()\n",
        "\t\tif(batch_idx % 25 == 0):\n",
        "\t\t\t# writer.add_scalar('Total Loss', loss, epoch*len(MixMatch_dataset) + batch_idx)\n",
        "\t\t\t# writer.add_scalar('Labelled Loss', cost_labelled, epoch*len(MixMatch_dataset) + batch_idx)\n",
        "\t\t\t# writer.add_scalar('Unlabelled Loss', cost_unlabelled, epoch*len(MixMatch_dataset) + batch_idx)\n",
        "\t\t\t# writer.add_scalars('Labelled and Unlabelled Loss', {'cost_labelled': cost_labelled,\n",
        "\t\t\t# \t\t\t\t\t\t\t\t\t\t\t\t\t'cost_unlabelled': cost_unlabelled}, \n",
        "\t\t\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t  epoch*len(MixMatch_dataset) + batch_idx)\n",
        "\t\t\t\n",
        "\t\t\ts = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f | Labelled loss: %.4f | Unlabelled loss: %.4f\\n'\n",
        "\t\t\t\t% (epoch, NUM_EPOCHS, batch_idx,\n",
        "\t\t\t\t\tlen(MixMatch_dataset)//BATCH_SIZE, loss, cost_labelled, cost_unlabelled))\n",
        "\t\t\twith open('drive/My Drive/MixMatch/Training Logs/train_log_'+str(NUM_LABELLED) + '.txt', 'a') as writefile:\n",
        "\t\t\t\twritefile.write(s)\n",
        "\t\n",
        "\ts = 'Time elapsed: %.2f min\\n' % ((time.time() - start_time)/60)\n",
        "\twith open('drive/My Drive/MixMatch/Training Logs/train_log_'+str(NUM_LABELLED) + '.txt', 'a') as writefile:\n",
        "\t\twritefile.write(s)\n",
        "\tmodel.eval()\n",
        "\ty_true = []\n",
        "\ty_pred = []\n",
        "\twith torch.set_grad_enabled(False):\n",
        "\t\tfor batch_idx, (img, label) in enumerate(testloader):\n",
        "\t\t\timg = img.to(DEVICE)\n",
        "\t\t\tlabel = label.to(DEVICE)\n",
        "\n",
        "\t\t\tlogits = model(img)\n",
        "\t\t\tprobas = nn.functional.softmax(logits, dim=1)\n",
        "\t\t\tpred = torch.argmax(probas, dim=1)\n",
        "\t\t\ty_true.extend(label.cpu().numpy())\n",
        "\t\t\ty_pred.extend(pred.cpu().numpy())\n",
        "\tacc = accuracy_score(y_true, y_pred)\n",
        "\tf1 = f1_score(y_true, y_pred)\n",
        "\t# if(batch_idx % 50 == 0):\n",
        "\t\t# writer.add_scalar('F1-score', f1, epoch)\n",
        "\t\t# writer.add_scalar('Accuracy', acc, epoch)\n",
        "\twith open('drive/My Drive/MixMatch/Training Logs/train_log_'+str(NUM_LABELLED) + '.txt', 'a') as writefile:\n",
        "\t\twritefile.write(\"Accuracy: \" + str(acc) + \"\\n\")\n",
        "\t\twritefile.write(\"F1_score: \" + str(f1) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdgVwvoMfAG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "41f94d88-8471-4ad8-9242-aad6c2107d85"
      },
      "source": [
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.set_grad_enabled(False):\n",
        "    correct_results = 0\n",
        "    for batch_idx, (img, label) in enumerate(testloader):\n",
        "        img = img.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        logits = model(img)\n",
        "        probas = nn.functional.softmax(logits, dim=1)\n",
        "        pred = torch.argmax(probas, dim=1)\n",
        "        y_true.extend(label.cpu().numpy())\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "print(f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGpXHuKvmRho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}